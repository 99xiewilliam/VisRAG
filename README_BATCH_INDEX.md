# VisRAG æ‰¹é‡ç´¢å¼•æŒ‡å—

æ‰¹é‡å¤„ç† `dataset` ç›®å½•ä¸­çš„æ‰€æœ‰ PDFï¼Œåˆ†åˆ«ç”Ÿæˆ**æ–‡æœ¬ embedding**å’Œ**vision tokens**ã€‚

---

## ğŸ“ è¾“å‡ºç»“æ„

```
output/
â”œâ”€â”€ chroma_db/                    # ChromaDB å‘é‡æ•°æ®åº“
â”‚   â”œâ”€â”€ text_pages/              # æ–‡æœ¬ embedding é›†åˆ
â”‚   â””â”€â”€ vision_pages/            # è§†è§‰ embedding é›†åˆ
â”œâ”€â”€ vision_tokens/               # åŸå§‹ vision token æ–‡ä»¶
â”‚   â”œâ”€â”€ DeepSeek-OCR-_Contexts_Optical_Compression/
â”‚   â”‚   â”œâ”€â”€ page_1.pt           # æ¯é¡µçš„ vision token
â”‚   â”‚   â”œâ”€â”€ page_2.pt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â””â”€â”€ index_report.json            # å¤„ç†æŠ¥å‘Š
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¤„ç†æ‰€æœ‰ PDFï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

```bash
cd VisRAG
python batch_index.py
```

è¿™ä¼šä½¿ç”¨ `config.yaml` ä¸­çš„é…ç½®ï¼Œå¤„ç† `dataset/` ä¸­çš„æ‰€æœ‰ PDFã€‚

### 2. ä½¿ç”¨æœ¬åœ° Embedding æ¨¡å‹ï¼ˆæ¨èç”¨äºæ‰¹é‡å¤„ç†ï¼‰

```bash
python batch_index.py --config config_batch_example.yaml
```

**ä¸ºä»€ä¹ˆæ¨èæœ¬åœ°æ¨¡å‹ï¼Ÿ**
- æ—  API è°ƒç”¨å»¶è¿Ÿ
- æ— ç½‘ç»œä¾èµ–
- æ—  API é™æµé—®é¢˜
- æˆæœ¬æ›´ä½

### 3. åªå¤„ç†å‰ N ä¸ª PDFï¼ˆæµ‹è¯•ç”¨ï¼‰

```bash
# åªå¤„ç†å‰ 2 ä¸ª PDF è¿›è¡Œæµ‹è¯•
python batch_index.py --max-pdfs 2
```

### 4. è‡ªå®šä¹‰è·¯å¾„

```bash
python batch_index.py \
    --dataset-dir /path/to/pdfs \
    --output-dir /path/to/output \
    --report /path/to/report.json
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é…ç½® 1ï¼šä½¿ç”¨ Hash Embeddingï¼ˆæœ€å¿«ï¼Œè´¨é‡è¾ƒä½ï¼‰

```yaml
# config.yaml
embedding:
  backend: "hash"
  dim: 256
```

**é€‚ç”¨åœºæ™¯**ï¼šå¿«é€Ÿæµ‹è¯•ã€å¯¹æ¯”å®éªŒ

### é…ç½® 2ï¼šä½¿ç”¨æœ¬åœ° Embeddingï¼ˆæ¨èï¼‰

```yaml
# config_batch_example.yaml
embedding:
  backend: "local"
  dim: 1024
  local:
    model_path: "/data/xwh/models/Qwen3-Embedding-0.6B"
    batch_size: 64      # å¢å¤§æ‰¹å¤„ç†æé«˜é€Ÿåº¦
    use_fp16: true      # å¼€å¯ fp16 åŠ é€Ÿ
```

**é€‚ç”¨åœºæ™¯**ï¼šç”Ÿäº§ç¯å¢ƒã€æ‰¹é‡å¤„ç†

### é…ç½® 3ï¼šä½¿ç”¨ OpenAI Embeddingï¼ˆé«˜è´¨é‡ï¼Œéœ€è”ç½‘ï¼‰

```yaml
embedding:
  backend: "openai"
  dim: 1536
  openai:
    model: "text-embedding-3-small"
    # dimensions: 256  # å¯é€‰é™ç»´
```

**é€‚ç”¨åœºæ™¯**ï¼šè¿½æ±‚æœ€é«˜è´¨é‡ã€PDF æ•°é‡å°‘

---

## ğŸ“Š å¤„ç†æŠ¥å‘Š

å¤„ç†å®Œæˆåä¼šç”Ÿæˆ JSON æŠ¥å‘Šï¼š

```json
{
  "total": 8,
  "success": 8,
  "failed": 0,
  "details": [
    {
      "doc_id": "DeepSeek-OCR-_Contexts_Optical_Compression",
      "pdf_path": "/data/xwh/VisRAG/dataset/DeepSeek-OCR- Contexts Optical Compression.pdf",
      "text": {"pages": 10, "success": true},
      "vision": {"pages": 10, "tokens_dir": "...", "success": true},
      "error": null
    }
  ]
}
```

---

## ğŸ” ç´¢å¼•åçš„ä½¿ç”¨

### æ–‡æœ¬æ£€ç´¢

```python
from src.pipeline import VisRAGPipeline

pipe = VisRAGPipeline("./output/chroma_db")
results = pipe.query_text("Transformer æ¶æ„", top_k=5)
```

### è§†è§‰æ£€ç´¢ï¼ˆä»¥å›¾æœå›¾ï¼‰

```python
results = pipe.query_vision_by_image("./query_image.png", top_k=5)
```

### ç›´æ¥æŸ¥è¯¢ ChromaDB

```python
from src.store import ChromaStore

store = ChromaStore("./output/chroma_db")

# æŸ¥çœ‹é›†åˆä¿¡æ¯
collection = store.get_collection("text_pages", dim=256)
print(collection.count())  # æ–‡æ¡£æ•°é‡
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ˜¾å­˜å ç”¨**ï¼š
   - æœ¬åœ° Embedding æ¨¡å‹éœ€è¦ GPU æ˜¾å­˜
   - Vision Encoder éœ€è¦è¾ƒå¤šæ˜¾å­˜
   - å¦‚æœæ˜¾å­˜ä¸è¶³ï¼Œå¯ä»¥åˆ†æ‰¹å¤„ç†

2. **å­˜å‚¨ç©ºé—´**ï¼š
   - Vision tokens ä¼šå ç”¨è¾ƒå¤šç£ç›˜ç©ºé—´
   - æ¯ä¸ª PDF é¡µçº¦ 1-5 MB
   - ç¡®ä¿ `output/vision_tokens/` æœ‰è¶³å¤Ÿç©ºé—´

3. **å¤„ç†æ—¶é—´ä¼°ç®—**ï¼ˆå–å†³äº GPUï¼‰ï¼š
   - Hash embedding: ~1 ç§’/10 é¡µ
   - Local embedding: ~5 ç§’/10 é¡µ
   - Vision tokens: ~10 ç§’/é¡µ

---

## ğŸ§ª æµ‹è¯•æµç¨‹

```bash
# 1. å…ˆæµ‹è¯• 1 ä¸ª PDF
python batch_index.py --max-pdfs 1

# 2. æ£€æŸ¥ç»“æœ
ls output/vision_tokens/
ls output/chroma_db/
cat output/index_report.json

# 3. æµ‹è¯•æŸ¥è¯¢
python main.py --persist output/chroma_db query_text --text "æµ‹è¯•æŸ¥è¯¢"

# 4. æ²¡é—®é¢˜åå¤„ç†å…¨éƒ¨
python batch_index.py
```
