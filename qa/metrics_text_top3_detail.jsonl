{"id": "DeepSeek-OCR- Contexts Optical Compression.pdf_p1_0", "question": "What are the two components of DeepSeek-OCR?", "reference": "DeepSeek-OCR consists of two components: DeepEncoder\nand DeepSeek3B-MoE-A570M as the decoder.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat are the two components of DeepSeek-OCR?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurificati\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What are the two components of DeepSeek-OCR?” 根据提供的材料，我需要仔细查看材料中是否有相关信息。\n\n首先，我快速浏览材料中的各个部分。材料分为三个部分，分别是关于RAG适应框架的论文、Orion-RAG的路径对齐混合检索方法，以及神经网络可编程性的统一主题。用户的问题是关于DeepSeek-OCR的组成部分，但材料中并没有提到DeepSeek-OCR这个具体的技术或系统。 \n\n接下来，我检查每个部分的标题和内容。第一部分的标题是“Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation”，讨论的是RAG适应框架，但没有提到DeepSeek-OCR。第二部分是关于Orion-RAG的路径对齐混合检索，同样没有涉及DeepSeek-OCR。第三部分讨论的是神经网络的可编程性，也不相关。\n\n材料中的参考文献和作者信息也没有提到DeepSeek-OCR。因此，根据提供的材料，无法找到关于DeepSeek-OCR的任何信息。用户的问题可能基于一个不存在于给定材料中的技术或系统，因此答案应该是无法从材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.015233949945593036, "em": 0.0, "meteor": 0.055957867017774866, "rouge_l": 0.013057671381936888}
{"id": "DeepSeek-OCR- Contexts Optical Compression.pdf_p1_1", "question": "What OCR precision is achieved when the compression ratio is < 10×?", "reference": "Experiments\nshow that when the number of text tokens is within 10 times that of vision tokens (i.e., a\ncompression ratio < 10×), the model can achieve decoding (OCR) precision of 97%.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat OCR precision is achieved when the compression ratio is < 10×?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurificat\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What OCR precision is achieved when the compression ratio is < 10×?” 根据提供的材料，我需要仔细查看是否有相关信息。\n\n首先，用户的问题是关于OCR精度和压缩比的关系。材料中提到的大部分内容都是关于语言模型、数据生成框架、检索增强生成（RAG）模型的限制和参考文献，还有一些关于神经网络可编程性的内容。我需要快速浏览这些材料，寻找是否有提到OCR精度或压缩比的相关信息。\n\n在材料中，第一段提到LlamaIndex的数据集生成框架，但没有提到OCR。接下来的段落讨论了Orion-RAG的路径对齐混合检索，但同样没有涉及OCR。然后是关于神经网络可编程性的内容，也没有提到OCR或压缩比。\n\n材料中的参考文献部分列举了多个研究，但所有引用的论文都是关于语言模型、数据生成、RAG技术、视觉模型等，没有涉及OCR技术或其精度指标。此外，材料中提到的压缩比可能是指数据压缩的比例，但没有具体说明在OCR中的应用或相关精度数据。\n\n因此，根据提供的材料，没有找到与OCR精度和压缩比关系相关的信息。用户的问题超出了材料中讨论的范围，因此无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.038751345532831, "em": 0.0, "meteor": 0.10275370555916888, "rouge_l": 0.025834230355220672}
{"id": "DeepSeek-OCR- Contexts Optical Compression.pdf_p1_2", "question": "What OCR accuracy is reported at a compression ratio of 20×?", "reference": "Even at a\ncompression ratio of 20×, the OCR accuracy still remains at about 60%.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat OCR accuracy is reported at a compression ratio of 20×?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devli\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What OCR accuracy is reported at a compression ratio of 20×?” 根据提供的材料，我需要仔细查看是否有相关信息。\n\n首先，用户提供的材料包括三部分：第一部分是关于神经网络可重编程性的论文，第二部分是关于领域特定数据生成框架的论文，第三部分是关于Orion-RAG的限制和参考文献。看起来这些材料都是学术论文，可能涉及不同的技术领域，比如自然语言处理、计算机视觉等。\n\n问题涉及OCR准确率和压缩比20×，但材料中并没有提到OCR技术、压缩比或准确率的相关内容。第一部分的论文讨论的是语言模型的训练和应用，第二部分是关于RAG适应性的数据生成框架，第三部分是关于Orion-RAG的限制和参考文献。这些内容都不涉及OCR技术或压缩比相关的数据。\n\n因此，根据提供的材料，无法找到与OCR准确率在压缩比20×下相关的信息。用户的问题超出了材料中提供的内容范围，所以答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.021786492374727667, "em": 0.0, "meteor": 0.07279843444227006, "rouge_l": 0.017429193899782137}
{"id": "DeepSeek-OCR- Contexts Optical Compression.pdf_p1_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1 | Figure (a) shows the compression ratio (number of text tokens in ground truth/number of vision tokens model used) testing on Fox [21] benchmark; Figure (b) shows performance comparisons on OmniDocBench [27]. DeepSeek-OCR can achieve state-of-the-art performance among end-to-end models enjoying the fewest vision tokens.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.03336809176225235, "em": 0.0, "meteor": 0.06291635825314583, "rouge_l": 0.022940563086548488}
{"id": "Domain-Specific Data Generation Framework for RAG Adaptation.pdf_p1_0", "question": "What is RAGen proposed for in this paper?", "reference": "Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat is RAGen proposed for in this paper?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p14]\nEllen M. Voorhees and Dawn M. Tice. 2000. Building\na question answering test collection. In Proceedings\nof the 23rd Annual International ACM SIGIR Confer-\nence on Research and Development in Information\nRetrieval, SIGIR ’00, page 200–207, New York, NY,\nUSA. Association for Computing Machinery.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023. Self-instruct: Aligning language\nmodels with self-generated instructions. In Proceed-\nings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 13484–13508, Toronto, Canada. Association\nfor Computational Linguistics.\nThomas\nWolf,\nLoubna\nBen\nAllal,\nLeandro\nvon\nWerra,\nLi\nJia,\nand\nArmel\nZebaze.\n2023.\nA dataset of python files from github.\nhttps://github.com/huggingface/blog/blob/\nmain/codeparrot.md?version=codeparrot/\ncodeparrot-valid-v2-near-dedup.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nChaojun Xiao, Pengle Zhang, Xu Han, Guangxuan Xiao,\nYankai Lin, Zhengyan Zhang, Zhiyuan Liu, Song\nHan, and Maosong Sun. 2024a. InfLLM: Unveiling\nthe intrinsic capacity of LLMs for understanding ex-\ntremely long sequences with training-free memory.\narXiv preprin\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What is RAGen proposed for in this paper?” 根据提供的材料，我需要仔细查看材料中的相关内容，找出与RAGen相关的部分。\n\n首先，用户提供的材料分为几个部分，看起来像是不同论文的引用或摘要。我需要逐一检查这些部分，寻找是否有提到RAGen的论文或相关的内容。\n\n在第一个材料中，标题是“Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction”，作者是A. Radford等人。这里讨论的是神经网络的可重编程性，涉及模型重编程、提示调优和提示指令。但这里并没有提到RAGen，所以可能与问题无关。\n\n接下来是第二个材料，标题是“Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation”，作者是Alex Mallen等人。这个标题直接提到了RAG（Retrieval-Augmented Generation），并且提到了一个领域特定的数据生成框架，用于适应RAG模型。这可能与问题相关，因为问题问的是RAGen提出的用途，而这里提到的RAG Adaptation可能就是RAGen的用途。\n\n第三个材料是“Long-Context_Language_Modeling_with_Parallel_Context_Encoding”，这里讨论的是长上下文建模和并行上下文编码，可能与语言模型的上下文处理有关，但没有提到RAGen。\n\n其他部分如LlamaIndex、OpenAI的文档等，可能与RAG相关，但没有直接提到RAGen。\n\n因此，根据第二个材料的标题“Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation”，可以推断RAGen可能是在这个论文中被提出，用于构建一个领域特定的数据生成框架，以适应RAG模型。因此，答案应该是该论文提出了一种领域特定的数据生成框架，用于RAG模型的适应。\n\n不过，需要确认是否有其他部分提到RAGen。例如，是否有其他论文的标题或内容涉及RAGen？但根据提供的材料，只有第二个部分明确提到RAG，而其他部分没有。因此，答案应基于第二个材料中的内容。\n</think>\n\n根据材料中的描述，**RAGen** 提出了一种**领域特定的数据生成框架**，用于**适应 Retrieval-Augmented Generation (RAG) 模型**。该框架旨在通过生成领域特定的训练数据，提升 RAG 模型在不同领域的泛化能力。  \n\n答案：RAGen 提出了一种领域特定的数据生成框架，用于适应 Retrieval-Augmented Generation (RAG) 模型。", "f1": 0.016096579476861165, "em": 0.0, "meteor": 0.06281407035175882, "rouge_l": 0.01408450704225352}
{"id": "Domain-Specific Data Generation Framework for RAG Adaptation.pdf_p1_1", "question": "How does RAGen produce domain-grounded QAC triples?", "reference": "Gen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nHow does RAGen produce domain-grounded QAC triples?\n\n材料:\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective state spaces.\nAlbert Gu, Karan Goel, and Christopher Re. 2022. Ef-\nficiently modeling long sequences with structured\nstate spaces. In International Conference on Learn-\ning Representations.\nKelvin Guu, Kento\n\n[Vision-centric_Token_Compression_in_Large_Language_Model p12]\n[32] Yuhuai Wu, Markus Norman Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing transformers.\nIn International Conference on Learning Representations.\n[33] Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, and Furu Wei. Augmenting\nlanguage models with long-term memory.\nIn Advances in Neural Information Processing Systems,\nvolume 36, 2024.\n[34] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of NAACL-HLT, volume 1, page 2, 2019.\n[35] Taku Kudo and John Richardson. SentencePiece: A simple and language independent subword tokenizer\nand detokenizer for neural text processing. In Proceedings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 66–71, 2018.\n[36] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with\nsubword units. In Association for Computational Linguistics, pages 1715–1725, 2016.\n[37] Elizabeth Salesky, David Etter, and Matt Post. Robust open-vocabulary translation from visual text\nrepresentations. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, 2021.\n[38] Tianyu Gao, Zirui Wang, Adithya Bhaskar, and Danqi Chen. Improving language understanding from\nscreenshots. arXiv preprint arXiv:2402.14073, 2024.\n[39] Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, and Hua Wu. Dual modalities of text:\nVisual and textual generative pre-training. arXiv preprint arXiv:2404.10710, 2024.\n[40] Jonas Lotz, Elizabeth Salesky, Phillip Rust, and Desmond Elliott. Text rendering strategies for pixel\nlanguage models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language\nProcessing, pages 10155–10172, 2023.\n[41] Chenghao Xiao, Zhuoxu Huang, Danlu Chen, G Thomas Hudson, Yizhi Li, Haoran Duan, Chenghua Lin,\nJie Fu, Jungong Han, and Noura Al Moubayed. Pixel sentence representation learning. arX\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurificat\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“How does RAGen produce domain-grounded QAC triples?” 根据提供的材料，我需要仔细查看材料中的相关内容，看看是否有提到RAGen生成域特定的QAC三元组的方法。\n\n首先，我注意到材料中有多篇论文，但大部分是关于语言模型的训练方法、注意力机制、数据集等。例如，有提到BERT、Mamba、SentencePiece等模型和方法。不过，用户的问题涉及RAGen，而材料中并没有直接提到RAGen这个术语。可能用户指的是某种特定的模型或方法，但材料中没有相关信息。\n\n接下来，我需要检查是否有任何部分提到RAGen或生成QAC三元组。在材料中，有一篇论文的标题是“Vision-centric_Token_Compression_in_Large_Language_Model p12”，但内容似乎与视觉模型压缩有关，可能与RAGen无关。另外，还有关于语言模型生成文本的论文，如“Enabling large language models to generate text with citations”（Gao等人，2023），但同样没有提到RAGen或QAC三元组。\n\n再看其他部分，比如“Neural_Network_Reprogrammability…”这篇论文讨论了模型的可重编程性，但也不涉及QAC三元组。此外，材料中提到的“Data engineering for scaling language models to 128k context”（2024年）可能与数据处理有关，但未提及RAGen。\n\n用户的问题可能涉及RAGen生成QAC三元组的方法，但材料中没有相关信息。因此，根据提供的材料，无法确定RAGen如何生成域特定的QAC三元组。需要确认是否有遗漏的部分，但根据现有材料，答案应为无法确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.02265705458290422, "em": 0.0, "meteor": 0.06033789219629928, "rouge_l": 0.014418125643666324}
{"id": "Domain-Specific Data Generation Framework for RAG Adaptation.pdf_p1_2", "question": "Which key components can RAGen optimize for RAG adaptation?", "reference": "including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhich key components can RAGen optimize for RAG adaptation?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“Which key components can RAGen optimize for RAG adaptation?” 根据提供的材料，我需要仔细查找相关信息。\n\n首先，用户提供的材料中有几段内容，其中一段是关于RAGen的描述。在[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]部分，提到RAGen是一个可扩展和模块化的框架，用于生成领域特定的问答-上下文（QAC）三元组，适用于不同的RAG适应方法。文中提到RAGen可以优化的关键组件包括LLM、检索器和嵌入模型等。此外，还提到模块化流水线包括语义分块、层次概念提取和多块检索，以及引入 curated distractor contexts 来促进稳健推理。\n\n需要确认是否还有其他可能的组件被提到。例如，材料中还提到“optimization of key components such as the LLM, retriever, and embedding model, etc.”，这明确指出了LLM、检索器和嵌入模型是可优化的组件。此外，模块化设计还包括其他组件，但问题问的是“key components”，所以主要关注这些被明确提到的。\n\n因此，答案应包括LLM、检索器和嵌入模型这三个组件。需要确保没有遗漏其他可能的组件，但根据材料内容，这些是明确提到的。\n</think>\n\nRAGen可以优化的关键组件包括：  \n1. **LLM（大语言模型）**  \n2. **检索器（Retriever）**  \n3. **嵌入模型（Embedding Model）**  \n\n此外，RAGen还支持通过模块化设计优化其他组件，如语义分块、层次概念提取和多块检索等，但核心优化目标明确指向上述三个关键组件。", "f1": 0.027484143763213533, "em": 0.0, "meteor": 0.10326852634544945, "rouge_l": 0.027484143763213533}
{"id": "Domain-Specific Data Generation Framework for RAG Adaptation.pdf_p3_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1: Overview of RAGen framework, a three-stage process that first extract document concepts and then construct question stems, and finally create Question-Answer-Context datasets. resentation learning, while generation modules typ- ically leverage pre-trained encoder–decoder mod-", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.03161222339304531, "em": 0.0, "meteor": 0.11297931698220126, "rouge_l": 0.02107481559536354}
{"id": "Long-Context Language Modeling with Parallel Context Encoding.pdf_p1_0", "question": "What is CEPE introduced for?", "reference": "We introduce\nContext Expansion with Parallel Encoding\n(CEPE\n), a framework that can be applied\nto any existing decoder-only LLMs to extend\ntheir context window.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat is CEPE introduced for?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p14]\nEllen M. Voorhees and Dawn M. Tice. 2000. Building\na question answering test collection. In Proceedings\nof the 23rd Annual International ACM SIGIR Confer-\nence on Research and Development in Information\nRetrieval, SIGIR ’00, page 200–207, New York, NY,\nUSA. Association for Computing Machinery.\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023. Self-instruct: Aligning language\nmodels with self-generated instructions. In Proceed-\nings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 13484–13508, Toronto, Canada. Association\nfor Computational Linguistics.\nThomas\nWolf,\nLoubna\nBen\nAllal,\nLeandro\nvon\nWerra,\nLi\nJia,\nand\nArmel\nZebaze.\n2023.\nA dataset of python files from github.\nhttps://github.com/huggingface/blog/blob/\nmain/codeparrot.md?version=codeparrot/\ncodeparrot-valid-v2-near-dedup.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander Rush. 2020. Trans-\nformers: State-of-the-art natural language processing.\nIn Proceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing: System\nDemonstrations, pages 38–45, Online. Association\nfor Computational Linguistics.\nChaojun Xiao, Pengle Zhang, Xu Han, Guangxuan Xiao,\nYankai Lin, Zhengyan Zhang, Zhiyuan Liu, Song\nHan, and Maosong Sun. 2024a. InfLLM: Unveiling\nthe intrinsic capacity of LLMs for understanding ex-\ntremely long sequences with training-free memory.\narXiv preprin\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What is CEPE introduced for?” 根据提供的材料，我需要仔细查看材料中的相关内容，看看是否有提到CEPE的定义或用途。\n\n首先，我快速浏览材料中的各个部分。材料看起来像是多篇学术论文和文章的引用列表，包括不同领域的研究，比如RAG适应性数据生成框架、神经网络可编程性、长上下文语言建模等。用户的问题涉及CEPE，但材料中并没有出现“CEPE”这个关键词。我需要确认是否在材料中存在拼写错误或缩写，比如是否是“CEPE”或其他类似术语。\n\n接下来，我检查每个条目。例如，第一部分提到“LlamaIndex. 2025. Llamaindex datasetgenerator.”，但这里没有CEPE。第二部分是关于神经网络可编程性的研究，作者包括A. Radford等人，但同样没有提到CEPE。第三部分是关于长上下文语言建模的论文，也没有CEPE的提及。\n\n继续检查其他部分，比如关于OpenAI的ChatGPT4o和Embedding API，以及一些关于LLM采用的论文，但依然没有发现CEPE的相关内容。最后，用户提供的材料中没有出现CEPE这个术语，因此无法从给定材料中确定其定义或用途。\n\n因此，答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.021436227224008578, "em": 0.0, "meteor": 0.05777777777777779, "rouge_l": 0.010718113612004289}
{"id": "Long-Context Language Modeling with Parallel Context Encoding.pdf_p1_1", "question": "To how many tokens does CEPE extend LLAMA-2's context window?", "reference": "it extends the con-\ntext window of LLAMA-2 to 128K tokens,\noffering 10× the throughput with only 1/6 of\nthe memory.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nTo how many tokens does CEPE extend LLAMA-2's context window?\n\n材料:\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective state spaces.\nAlbert Gu, Karan Goel, and Christopher Re. 2022. Ef-\nficiently modeling long sequences with structured\nstate spaces. In International Conference on Learn-\ning Representations.\nKelvin Guu, Kento\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Vision-centric_Token_Compression_in_Large_Language_Model p12]\n[32] Yuhuai Wu, Markus Norman Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing transformers.\nIn International Conference on Learning Representations.\n[33] Weizhi Wang, Li Dong, Hao Cheng, Xiaodong Liu, Xifeng Yan, Jianfeng Gao, and Furu Wei. Augmenting\nlanguage models with long-term memory.\nIn Advances in Neural Information Processing Systems,\nvolume 36, 2024.\n[34] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep bidirectional\ntransformers for language understanding. In Proceedings of NAACL-HLT, volume 1, page 2, 2019.\n[35] Taku Kudo and John Richardson. SentencePiece: A simple and language independent subword tokenizer\nand detokenizer for neural text processing. In Proceedings of the 2018 Conference on Empirical Methods\nin Natural Language Processing, pages 66–71, 2018.\n[36] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with\nsubword units. In Association for Computational Linguistics, pages 1715–1725, 2016.\n[37] Elizabeth Salesky, David Etter, and Matt Post. Robust open-vocabulary translation from visual text\nrepresentations. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language\nProcessing, 2021.\n[38] Tianyu Gao, Zirui Wang, Adithya Bhaskar, and Danqi Chen. Improving language understanding from\nscreenshots. arXiv preprint arXiv:2402.14073, 2024.\n[39] Yekun Chai, Qingyi Liu, Jingwu Xiao, Shuohuan Wang, Yu Sun, and Hua Wu. Dual modalities of text:\nVisual and textual generative pre-training. arXiv preprint arXiv:2404.10710, 2024.\n[40] Jonas Lotz, Elizabeth Salesky, Phillip Rust, and Desmond Elliott. Text rendering strategies for pixel\nlanguage models. In Proceedings of the 2023 Conference on Empirical Methods in\n\n答案:\nassistant\n<think>\n好的，我需要回答用户的问题：“To how many tokens does CEPE extend LLAMA-2's context window?” 即CEPE扩展了LLAMA-2的上下文窗口到多少个token。\n\n首先，我需要仔细查看提供的材料，寻找与CEPE和LLAMA-2上下文窗口相关的信息。材料中有很多学术论文和会议论文的引用，但大部分内容似乎与模型训练、优化技术、提示工程等有关，没有直接提到CEPE或LLAMA-2的具体上下文窗口扩展数量。\n\n接下来，我注意到材料中有一段提到“CEPE extend LLAMA-2's context window”，但这句话出现在材料的中间部分，可能是在某个引用中提到的。不过，根据提供的材料内容，没有具体的数字或技术细节说明扩展到多少个token。例如，材料中可能有其他研究讨论上下文窗口，但没有明确提到CEPE的具体扩展数值。\n\n此外，材料中多次提到不同模型的上下文窗口，比如BERT、Mamba、LLAMA-2等，但没有明确说明CEPE对LLAMA-2的上下文窗口进行了多少token的扩展。因此，需要确认是否有任何部分直接回答这个问题。\n\n由于材料中没有提供关于CEPE扩展LLAMA-2上下文窗口的具体数值，因此无法从给定材料中确定答案。用户的问题需要具体的数字，而材料中没有相关信息，因此应回答“无法从给定材料中确定”。\n</think>\n\n无法从给定材料中确定。", "f1": 0.0273972602739726, "em": 0.0, "meteor": 0.08027251778378922, "rouge_l": 0.01685985247629083}
{"id": "Long-Context Language Modeling with Parallel Context Encoding.pdf_p1_2", "question": "What throughput and memory improvements are claimed for CEPE?", "reference": "offering 10× the throughput with only 1/6 of\nthe memory.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat throughput and memory improvements are claimed for CEPE?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanaya\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What throughput and memory improvements are claimed for CEPE?” 根据提供的材料，我需要仔细查找是否有相关信息。\n\n首先，用户提供的材料包括几篇学术论文和一些参考文献，但看起来大部分内容都是关于神经网络可重编程性、提示调优、视觉语言模型等主题。我需要快速浏览这些材料，寻找是否有提到CEPE（可能是指某种特定的模型或技术）的吞吐量和内存改进。\n\n在材料中，第一篇提到的论文是关于神经网络可重编程性的，作者包括A. Radford等人，但没有提到CEPE。接下来的几篇论文涉及不同的主题，比如Orion-RAG、领域特定的数据生成框架、LlamaIndex等，但也没有提到CEPE。此外，还有关于OpenAI模型的文档，如ChatGPT-4o和文本嵌入API，但同样没有提到CEPE。\n\n材料中没有出现“CEPE”这个术语，可能用户指的是某个特定的模型或技术，但根据提供的文本，无法找到相关的信息。因此，无法从给定的材料中确定CEPE的吞吐量和内存改进情况。\n\n因此，正确的回答应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.010893246187363835, "em": 0.0, "meteor": 0.02525252525252526, "rouge_l": 0.010893246187363835}
{"id": "Long-Context Language Modeling with Parallel Context Encoding.pdf_p1_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1: A comparison between CEPE and other tech- niques of extending LLMs’ context window, including YARN (Peng et al., 2024), STREAMINGLLM (Xiao et al., 2024b), and REPLUG (Shi et al., 2024). CEPE", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.03609341825902335, "em": 0.0, "meteor": 0.11490343988952782, "rouge_l": 0.03184713375796178}
{"id": "Neural Network Reprogrammability- A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction.pdf_p1_0", "question": "What does the survey introduce as a unifying framework?", "reference": "This survey introduces neural network reprogramma-\nbility as a unifying framework that bridges mainstream model adaptation techniques–model\nreprogramming, prompt tuning, and prompt instruction–previously fragmented research areas\nyet converges on a shared principle: repurposing a pre-trained model by manipulating infor-\nmation at the interfaces while keeping the model parameters frozen.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat does the survey introduce as a unifying framework?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurific\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What does the survey introduce as a unifying framework?” 根据提供的材料，我需要仔细查找是否有提到调查引入的统一框架。\n\n首先，我回顾用户提供的材料，注意到材料中有几篇学术论文，但大部分是关于RAG适应、神经网络可编程性等主题。在材料的开头部分，有一篇题为“Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation”的论文，作者是Chris Xing Tian等。这篇论文的摘要提到RAG结合了语言理解和推理能力，需要专门的、上下文丰富的训练数据。他们提出了RAGen框架，用于生成领域特定的问答-上下文三元组，支持多种RAG适应策略，包括优化LLM、检索器和嵌入模型等。这里提到的RAGen可能是一个统一的框架，用于生成领域特定的数据。\n\n接下来，我需要确认是否有其他部分提到“survey”或“unifying framework”。在材料中，有一篇题为“Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_Instruction”的论文，作者是A. Radford等人，讨论了模型可编程性、提示调优等主题。但这里并没有提到调查引入的统一框架，而是讨论模型可编程性的统一主题。\n\n再检查其他部分，比如关于Qwen2.5的技术报告，以及一些关于RAG的其他论文，但没有提到调查或统一框架。因此，唯一提到的统一框架是在RAGen框架中，即RAGen作为生成领域特定数据的框架。\n\n因此，答案应该是RAGen，即RAG Adaptation Generation Framework，或者根据材料中的具体名称，可能需要更准确的翻译。根据材料中的描述，RAGen是用于生成QAC三元组的框架，因此可以确定答案是RAGen。\n</think>\n\nThe survey introduces **RAGen** as the unifying framework. This framework is designed to generate domain-grounded question–answer–context (QAC) triples tailored for diverse RAG adaptation approaches, combining key concept identification, Bloom’s Taxonomy-guided question generation, and context-based answer extraction.", "f1": 0.04505386875612145, "em": 0.0, "meteor": 0.15181949658890045, "rouge_l": 0.02742409402546523}
{"id": "Neural Network Reprogrammability- A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction.pdf_p1_1", "question": "What shared principle do these methods converge on?", "reference": "converges on a shared principle: repurposing a pre-trained model by manipulating infor-\nmation at the interfaces while keeping the model parameters frozen.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat shared principle do these methods converge on?\n\n材料:\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p32]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nC. Zhang, J. Cho, F. D. Puspitasari, S. Zheng, C. Li, Y. Qiao, T. Kang, X. Shan, C. Zhang, C. Qin, F. Rameau,\nL.-H. Lee, S.-H. Bae, and C. S. Hong. A survey on segment anything model (sam): Vision foundation\nmodel meets prompt engineering. arXiv preprint arXiv:2306.06211, 2023a.\nJ. Zhang, B. I. Rubinstein, J. Zhang, and F. Liu. One stone, two birds: Enhancing adversarial defense through\nthe lens of distributional discrepancy. In ICML, 2025.\nN. Zhang, L. Li, X. Chen, S. Deng, Z. Bi, C. Tan, F. Huang, and H. Chen. Differentiable prompt makes\npre-trained language models better few-shot learners. In ICLR, 2022.\nT. Zhang, X. Li, H. Fei, H. Yuan, S. Wu, S. Ji, C. C. Loy, and S. Yan. Omg-llava: Bridging image-level,\nobject-level, pixel-level reasoning and understanding. In NeurIPS, 2024a.\nY. Zhang, K. Zhou, and Z. Liu. What makes good examples for visual in-context learning? In NeurIPS.\nCurran Associates, Inc., 2023b.\nY. Zhang, Y. Dong, S. Zhang, T. Min, H. Su, and J. Zhu. Exploring the transferability of visual prompting for\nmultimodal large language models. In CVPR, pages 26562–26572, 2024b.\nY. Zhang, H. Li, Y. Yao, A. Chen, S. Zhang, P.-Y. Chen, M. Wang, and S. Liu. Visual prompting reimagined:\nThe power of activation prompts. 2024c.\nW. X. Zhao, X. Liu, J. Zhang, Y. Zhang, K. Zhou, and J.-R. Wen. A comprehensive survey on pretrained\nfoundation models: A history from BERT to ChatGPT. arXiv preprint arXiv:2302.09419, 2023.\nZ. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh. Calibrate before use: Improving few-shot performance\nof language models. In ICML, 2021.\nH. Zheng, Q. Wang, Z. F\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What shared principle do these methods converge on?” 根据提供的材料，我需要仔细分析材料中的内容，找出这些方法共有的原则。\n\n首先，我注意到材料中有两段内容，分别是关于Orion-RAG和Neural Network Reprogrammability的。用户的问题可能涉及这两个部分中的方法，但需要确认。\n\n首先看Orion-RAG的部分。材料中提到，Orion-RAG的局限性包括依赖于源文本中的可提取实体，当段落高度抽象或缺乏明确主题时，生成的路径可能变得泛化或稀疏，影响索引效率。此外，框架对超参数配置敏感，如分块大小和剪枝阈值，需要领域特定调整。还有，重写和路径生成依赖于提示设计，提示的小变化会影响生成的标签粒度，进而影响下游检索精度。这些限制指出，虽然存在挑战，但为未来优化和鲁棒性研究提供了方向。\n\n接下来是Neural Network Reprogrammability部分，这里提到语言模型是无监督的多任务学习者，OpenAI博客2019年提到。还有其他研究，如学习可转移的视觉模型、多任务提示训练、视觉提示工程等。这些研究似乎集中在模型的可重编程性，即通过提示调整模型的行为，使其适应不同任务。例如，AutoPrompt方法通过自动生成提示来从语言模型中提取知识，而Vl-adapter则进行参数高效迁移学习。此外，还有关于提示报告的系统调查，以及不同提示策略的研究。\n\n现在需要找出这两个部分中方法共有的原则。Orion-RAG的问题涉及路径生成和提示设计，而Neural Network Reprogrammability则涉及模型的可重编程性，通过提示调整。但问题中的“这些方法”可能指的是材料中提到的两种方法，即Orion-RAG和Neural Network Reprogrammability中的方法。\n\n不过，用户的问题可能更关注于材料中提到的两种方法的共同点。例如，Orion-RAG的路径生成和提示设计，而Neural Network Reprogrammability的提示调整。但需要看是否有共同的原则。\n\n或者，可能用户的问题中的“这些方法”指的是材料中提到的所有方法，包括Orion-RAG和Neural Network Reprogrammability中的方法。但需要仔细分析。\n\n在Orion-RAG的材料中，提到的限制包括依赖实体、超参数敏感性、提示设计影响结果。而Neural Network Reprogrammability的材料中，提到的共同点是模型的可重编程性，通过提示调整模型行为。因此，可能这两个方法都涉及提示设计或调整模型参数以适应不同任务，但需要确认。\n\n不过，Orion-RAG的路径生成和提示设计可能属于不同的方面，而Neural Network Reprogrammability更侧重于模型的可重编程性。因此，可能它们的共同点在于使用提示来调整模型行为，但需要具体分析。\n\n或者，可能问题中的“这些方法”指的是材料中提到的两种方法，即Orion-RAG和Neural Network Reprogrammability中的方法，它们的共同点在于使用提示或调整模型参数来优化性能。但需要更仔细的分析。\n\n例如，Orion-RAG的路径生成和提示设计可能属于不同的方面，而Neural Network Reprogrammability中的方法涉及提示调整。因此，可能它们的共同点是使用提示来优化模型表现，但需要确认。\n\n不过，可能用户的问题中的“这些方法”指的是材料中提到的两种方法，即Orion-RAG和Neural Network Reprogrammability中的方法，它们", "f1": 0.019646365422396856, "em": 0.0, "meteor": 0.09267688261771102, "rouge_l": 0.009823182711198428}
{"id": "Neural Network Reprogrammability- A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction.pdf_p1_2", "question": "What are the four key dimensions in the taxonomy?", "reference": "across four key dimensions: manipulation format (fixed or learnable),\nlocation (interfaces where manipulations occur), operator (how they are applied), and output\nalignment requirement (post-processing needed to align outputs with downstream tasks).", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat are the four key dimensions in the taxonomy?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKrist\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What are the four key dimensions in the taxonomy?” 根据提供的材料，我需要仔细查看材料中的内容，看看是否有提到四个关键维度的分类。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、限制、参考文献等。我需要逐一检查这些部分，寻找与“taxonomy”相关的关键词或内容。\n\n在材料中，第一部分是关于RAG适应的领域特定数据生成框架，作者们提出了RAGen框架，用于生成领域特定的问题-答案-上下文（QAC）三元组。这里提到的“Bloom’s Taxonomy-inspired principles”可能与分类有关，但需要确认是否涉及四个关键维度。\n\n接下来，我注意到在材料的某个部分，提到“Bloom’s Taxonomy”被用来指导生成问题，这可能与分类理论有关。但问题中的“taxonomy”是否指Bloom的分类，还是其他类型的分类呢？\n\n另外，材料中还提到了其他技术细节，如模块化管道、语义分块、层次概念提取、多块检索等，但这些可能属于RAGen框架的组成部分，而不是分类维度。\n\n在参考文献部分，有提到一些研究，如关于LLM在不同领域的应用，但没有直接提到四个关键维度的分类。\n\n再仔细检查材料中的关键词，是否有“taxonomy”相关的描述。例如，在摘要部分提到“Bloom’s Taxonomy-inspired principles”，这可能是指Bloom的分类理论，但问题中的“four key dimensions”是否指的是Bloom的四个分类维度呢？\n\nBloom的分类维度通常包括认知、情感、动作等，但具体四个维度可能需要确认。不过，材料中并没有明确说明这四个维度是Bloom的四个，而是提到基于Bloom的原理生成问题。\n\n因此，可能材料中提到的四个关键维度是指基于Bloom的分类原则，但需要确认是否在材料中有明确的四个维度的描述。然而，材料中并没有明确列出四个关键维度，只是提到使用Bloom的原理来生成问题。\n\n因此，可能无法从材料中确定四个关键维度，或者材料中提到的四个维度是基于Bloom的分类，但没有明确说明四个具体维度。因此，答案可能无法确定，或者需要根据材料中的信息推断。\n\n不过，用户的问题可能希望答案是基于材料中的内容，而材料中提到的四个维度可能是指Bloom的四个分类维度，但材料中并没有明确说明。因此，可能需要回答无法确定，或者根据材料中的信息推测。\n\n但根据材料中的描述，作者提到使用Bloom’s Taxonomy-inspired principles来生成问题，这可能暗示四个关键维度，但材料中并没有明确列出四个维度，因此无法确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.027926960257787323, "em": 0.0, "meteor": 0.09402611334439123, "rouge_l": 0.017185821697099892}
{"id": "Neural Network Reprogrammability- A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction.pdf_p2_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1 | Paradigm shift from conventional parameter-centric adaptation (i.e., modifying model parameters) to reprogrammability-centric adaptation (i.e., modifying input data and model output). This represents a shift in thought from modifying the model to align with the task to modifying the task to align with the model. fine-tuning, where a substantial portion, if not all, of the model’s parameters are updated using task-specific", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.06378600823045268, "em": 0.0, "meteor": 0.13255258266895417, "rouge_l": 0.037037037037037035}
{"id": "Orion-RAG- Path-Aligned Hybrid Retrieval for Graphless Data.pdf_p1_0", "question": "What challenge does RAG face in fragmented data scenarios?", "reference": "it encounters significant challenges in practi-\ncal scenarios where data is inherently discrete\nand fragmented.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat challenge does RAG face in fragmented data scenarios?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devli\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What challenge does RAG face in fragmented data scenarios?” 根据提供的材料，我需要仔细查找相关部分。\n\n首先，用户提供的材料包括三篇不同的文章，分别是关于神经网络可编程性的、领域特定的数据生成框架以及Orion-RAG的局限性。我需要逐一查看这些材料，看看是否有提到RAG在碎片化数据场景下的挑战。\n\n第一篇材料主要讨论的是RAG结合了大型语言模型的语义理解和推理能力，以及外部检索，用于生成领域特定的回答。但这里并没有提到碎片化数据的问题，可能更多是关于适应领域设置的需求。\n\n第二篇材料是关于RAG适应领域的数据生成框架RAGen，提到需要专门的、上下文丰富的训练数据，以适应领域特定的设置。这里提到需要生成领域相关的问答-上下文三元组，但并没有直接提到碎片化数据的问题。\n\n第三篇材料是关于Orion-RAG的局限性，其中提到在源文本中存在可提取实体的情况下，性能较好，但当文本高度抽象或缺乏明确主题时，生成的路径可能变得泛化或稀疏，影响索引效率。这可能涉及到碎片化数据的问题，因为如果数据碎片化，可能无法有效提取实体，导致路径生成问题。\n\n因此，第三篇材料中的“fragmented data scenarios”可能指的是数据碎片化的情况，导致RAG在处理时遇到挑战，比如无法有效提取实体，从而影响路径生成的效率。因此，答案应该是Orion-RAG在碎片化数据场景下面临挑战，即无法有效提取实体，导致路径生成问题。\n\n需要确认是否有其他材料提到类似的问题，但根据现有材料，第三篇是唯一提到碎片化数据的。因此，答案应基于这一点。\n</think>\n\n无法从给定材料中确定。  \n\n**原因**：材料中未明确提及RAG在碎片化数据场景下的具体挑战。虽然第三篇材料提到Orion-RAG在“高度抽象或缺乏明确主题”的文本中可能生成泛化或稀疏的路径，但这是针对特定场景（如文本抽象性）的限制，而非直接针对“碎片化数据”的挑战。材料未明确将碎片化数据与RAG的特定问题关联。", "f1": 0.017297297297297298, "em": 0.0, "meteor": 0.04306220095693781, "rouge_l": 0.015135135135135138}
{"id": "Orion-RAG- Path-Aligned Hybrid Retrieval for Graphless Data.pdf_p1_1", "question": "What is the core insight of Orion-RAG?", "reference": "Our\ncore insight is simple yet effective: we do\nnot need heavy algorithms to organize this\ndata.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat is the core insight of Orion-RAG?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanaya\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What is the core insight of Orion-RAG?” 根据提供的材料，我需要仔细查看相关部分，找出核心见解。\n\n首先，用户提供的材料中有两部分关于Orion-RAG的信息。第一部分是标题为“Orion-RAG - Path-Aligned Hybrid Retrieval for Graphless Data”的文章，其中提到了局限性，比如依赖可提取实体、超参数敏感性以及提示设计的影响。第二部分是参考文献，可能包含更多相关研究，但用户的问题可能集中在Orion-RAG的核心见解上。\n\n在第一部分的“Limitations”部分，作者提到Orion-RAG在不同数据集上的表现，但存在一些限制。例如，它需要源文本中有可提取的实体，否则生成的路径可能变得泛化或稀疏，影响效率。另外，超参数配置如分块大小和剪枝阈值会影响性能，需要领域特定调整。还有提示设计影响生成的标签粒度，进而影响下游检索精度。\n\n核心见解可能在于Orion-RAG通过路径对齐的混合检索方法处理图结构数据，但需要依赖可提取实体和优化提示设计。不过，材料中并没有明确说明Orion-RAG的核心见解是什么，而是更多讨论其局限性和优化方向。\n\n需要确认是否有其他部分提到Orion-RAG的核心思想。例如，是否有其他段落或引用中提到其核心见解？在提供的材料中，除了限制部分，其他部分如参考文献可能没有直接涉及Orion-RAG的核心见解，而是其他研究的引用。\n\n因此，可能需要总结材料中提到的Orion-RAG的局限性，但用户的问题是关于核心见解，而材料中并没有明确给出Orion-RAG的核心见解，而是指出其存在的问题和优化方向。因此，可能无法从材料中确定答案，应回答无法确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.014973262032085561, "em": 0.0, "meteor": 0.05933706816059758, "rouge_l": 0.012834224598930482}
{"id": "Orion-RAG- Path-Aligned Hybrid Retrieval for Graphless Data.pdf_p1_2", "question": "What relative improvement is reported on FinanceBench?", "reference": "25.2% relative improvement over\nstrong baselines.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat relative improvement is reported on FinanceBench?\n\n材料:\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurificati\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What relative improvement is reported on FinanceBench?” 根据提供的材料，我需要仔细查看材料中的相关内容。\n\n首先，我快速浏览材料中的各个部分。材料包括几篇学术论文，分别讨论了Orion-RAG、Domain-Specific Data Generation Framework for RAG Adaptation以及Neural Network Reprogrammability等主题。用户的问题是关于FinanceBench的相对改进情况，但材料中并没有提到FinanceBench这个具体的数据集或实验。\n\n接下来，我检查每个材料的标题和摘要。第一篇材料是关于Orion-RAG的局限性，提到了数据实体提取、超参数配置和提示设计的影响。第二篇讨论的是RAG适应的领域特定数据生成框架，第三篇涉及神经网络的可重编程性。这些内容都没有提到FinanceBench，也没有任何关于该数据集的改进或比较的信息。\n\n此外，用户的问题可能涉及某个特定的研究或实验，但根据提供的材料，没有相关的内容。因此，无法从给定的材料中找到答案。需要确认是否有遗漏的部分，但根据现有信息，答案应该是无法确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.006622516556291392, "em": 0.0, "meteor": 0.026565026565026573, "rouge_l": 0.006622516556291392}
{"id": "Orion-RAG- Path-Aligned Hybrid Retrieval for Graphless Data.pdf_p2_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1: System overview of Orion-RAG. (1) The Path-Annotation Data Augmentation subsystem (left) employs dual-layer labeling agents to construct hierarchical navigation paths from fragmented text, enabling real-time incremental indexing. (2) The Multi-Layer Hybrid Retrieval subsystem (right) utilizes these paths as explicit logical signposts, integrating sparse and dense search to guide the generator towards accurate and interpretable answers.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.041279669762641906, "em": 0.0, "meteor": 0.10062456627342126, "rouge_l": 0.02683178534571723}
{"id": "UltraRAG- A Modular and Automated Toolkit for Adaptive Retrieval-Augmented Generation.pdf_p1_0", "question": "What limitation of existing RAG toolkits does UltraRAG address?", "reference": "However,\nmany existing RAG toolkits lack support for\nknowledge adaptation tailored to specific ap-\nplication scenarios.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat limitation of existing RAG toolkits does UltraRAG address?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p22]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nsizes, pre-training data); a wide array of target tasks, spanning different modalities (text, vision, multi-\nmodal), varying levels of abstraction, and diverse degrees of similarity/dissimilarity to the source\nmodel’s original task(s); standardized conditions for evaluation: data limitations (few-shot, zero-shot\nreprogramming), signal-to-noise ratios, presence of distribution shifts between reprogrammable data\nand test data, and computational budgets for learning the reprogrammed solution.\n• Defining Appropriate Baselines: Clear guidelines are necessary for choosing appropriate baselines\nwhen evaluating RCA methods. These guidelines should consider factors such as the number of\ntrainable parameters (if any), computational cost (e.g., FLOPs for training and inference), and the type\nof access to the pre-trained model (e.g., white-box vs. black-box).\n• Setting up Evaluation Metrics: Evaluations should extend beyond task-specific accuracy. Crucially,\nreasonable additional dimensions include but are not limited to robustness and stability, program\nefficiency, computational gains, and transferability of the RCA solution across different tasks.\nWithout rigorous evaluation frameworks, assessing true progress in RCA research will remain challenging,\npotentially leading to fragmented efforts and incomparable results.\n5.3. Limitations of Existing Programs\nWhile the concept of reprogrammability is appealing for its efficiency and potential, current techniques,\nparticularly those involving “prompts” (whether hard textual prompts or learned soft prompts), still exhibit\npractical limitations:\n• Data Efficiency: Although RCA avoids fin\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What limitation of existing RAG toolkits does UltraRAG address?” 根据提供的材料，我需要仔细查找相关信息。\n\n首先，用户提供的材料中有三个部分，分别是关于RAG适应框架、Orion-RAG的局限性以及神经网络可重编程性。问题集中在UltraRAG的局限性，所以需要查看是否有提到UltraRAG的内容。\n\n在第一个材料中，提到的是RAGen框架，它是一个用于生成领域特定的问答-上下文三元组的框架，支持多种RAG适应策略，包括优化LLM、检索器和嵌入模型等。这里提到RAGen的模块化管道包括语义分块、层次概念提取和多块检索，以及引入 curated distractor contexts 来促进稳健推理。但这里并没有直接提到UltraRAG，而是RAGen。\n\n第二个材料是关于Orion-RAG的局限性，指出其依赖于源文本中的可提取实体，如果文本抽象或缺乏明确主题，生成的路径可能变得通用或稀疏，影响效率。此外，还提到超参数配置敏感性和提示设计对性能的影响。但这里也没有提到UltraRAG。\n\n第三个材料讨论的是神经网络可重编程性，提到现有程序的局限性，如数据效率、评估框架等，但同样没有提到UltraRAG。\n\n因此，材料中没有直接提到UltraRAG的局限性。用户的问题可能是指UltraRAG如何解决现有RAG工具的局限性，但根据提供的材料，没有相关信息。因此，答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.025056947608200455, "em": 0.0, "meteor": 0.059642147117296235, "rouge_l": 0.02050113895216401}
{"id": "UltraRAG- A Modular and Automated Toolkit for Adaptive Retrieval-Augmented Generation.pdf_p1_1", "question": "What does UltraRAG automate throughout the entire workflow?", "reference": "we propose UltraRAG, a RAG toolkit that auto-\nmates knowledge adaptation throughout the en-\ntire workflow, from data construction and train-\ning to evaluation, while ensuring ease of use.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat does UltraRAG automate throughout the entire workflow?\n\n材料:\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective state spaces.\nAlbert Gu, Karan Goel, and Christopher Re. 2022. Ef-\nficiently modeling long sequences with structured\nstate spaces. In International Conference on Learn-\ning Representations.\nKelvin Guu, Kento\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What does UltraRAG automate throughout the entire workflow?” 根据提供的材料，我需要仔细查看材料中的相关内容，看看是否有提到UltraRAG以及它在整个工作流程中自动化的部分。\n\n首先，我注意到用户提供的材料中有几个部分，分别涉及不同的研究论文和项目。例如，第一部分是关于Adapting language models to compress contexts的论文，作者是Alexis Chevalier等人，发表在2023年的会议上。第二部分是Orion-RAG的路径对齐混合检索方法，作者是Kelvin Guu等人，第三部分是关于领域特定数据生成框架的论文，作者是Chris Xing Tian等人。\n\n现在，我需要检查这些材料中是否有提到UltraRAG。在用户提供的材料中，没有出现“UltraRAG”这个关键词。第一部分的论文标题是“Adapting language models to compress contexts”，第二部分是“Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data”，第三部分是“Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation”。这些标题中没有提到UltraRAG。\n\n接下来，我需要确认用户是否可能将UltraRAG与其他项目混淆，或者是否有其他部分可能被遗漏。例如，是否有其他部分的标题或内容提到UltraRAG？在用户提供的材料中，没有其他部分涉及UltraRAG。因此，根据现有的材料，无法找到关于UltraRAG的信息。\n\n因此，根据材料中的内容，无法确定UltraRAG在工作流程中自动化的部分。用户的问题可能基于一个不存在于给定材料中的概念或项目，所以答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.034594594594594595, "em": 0.0, "meteor": 0.09572688582936194, "rouge_l": 0.02162162162162162}
{"id": "UltraRAG- A Modular and Automated Toolkit for Adaptive Retrieval-Augmented Generation.pdf_p1_2", "question": "What does UltraRAG's WebUI enable according to the abstract?", "reference": "UltraRAG features a user-friendly WebUI that\nstreamlines the RAG process, allowing users\nto build and optimize systems without coding\nexpertise.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat does UltraRAG's WebUI enable according to the abstract?\n\n材料:\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective state spaces.\nAlbert Gu, Karan Goel, and Christopher Re. 2022. Ef-\nficiently modeling long sequences with structured\nstate spaces. In International Conference on Learn-\ning Representations.\nKelvin Guu, Kento\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Dev\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What does UltraRAG's WebUI enable according to the abstract?” 根据提供的材料，我需要仔细查看材料中的相关内容，看看是否有提到UltraRAG的WebUI及其功能。\n\n首先，我注意到材料中有多个部分，包括学术论文的摘要和参考文献。用户的问题可能涉及某个特定的论文摘要，但根据提供的材料，我需要寻找是否有提到UltraRAG的WebUI。\n\n快速浏览材料，发现第一部分是关于Long-Context_Language_Modeling_with_Parallel_Context_Encoding的论文，作者是Alexis Chevalier等人，讨论的是适应语言模型压缩上下文的方法。接着是其他论文的引用，比如Neural Network Reprogrammability，然后是Orion-RAG的限制和参考文献。\n\n在Orion-RAG的部分，提到了Limitations，但并没有提到UltraRAG的WebUI。用户的问题中的UltraRAG可能是指Orion-RAG，但材料中并没有明确说明。此外，材料中没有出现UltraRAG这个词，可能用户有拼写错误或者混淆了不同的论文。\n\n因此，根据提供的材料，无法找到关于UltraRAG的WebUI的描述。所以答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.014957264957264956, "em": 0.0, "meteor": 0.04595588235294119, "rouge_l": 0.010683760683760684}
{"id": "UltraRAG- A Modular and Automated Toolkit for Adaptive Retrieval-Augmented Generation.pdf_p2_3", "question": "According to Table 1, what does it describe?", "reference": "Table 1: Comparison of UltraRAG Features with Other RAG Frameworks. User-Friendly WebUI. UltraRAG provides an intuitive WebUI that allows users to easily deploy RAG systems and efficiently process knowledge", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Table 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective st\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Table 1, what does it describe?” 用户提供的材料中包含多个学术论文的章节，但并没有提到任何具体的表格1。首先，我需要仔细检查材料中的所有部分，寻找是否有表格的提及。\n\n材料中的第一部分是关于Domain-Specific Data Generation Framework for RAG Adaptation，其中提到了RAGen框架，但并没有提到表格1。接下来的章节是关于LlamaIndex、OpenAI的模型、以及一些其他研究论文的引用，但同样没有提到表格1。\n\n用户可能误以为材料中存在表格1，但实际上材料中并没有任何表格的描述。因此，根据给定的材料，无法确定表格1的内容或描述。需要确认是否在材料中存在表格，但根据提供的文本，没有发现表格的提及。因此，正确的回答应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.026548672566371678, "em": 0.0, "meteor": 0.06602112676056339, "rouge_l": 0.022123893805309734}
{"id": "Vision-centric Token Compression in Large Language Model.pdf_p1_0", "question": "Why is token compression considered indispensable in this paper?", "reference": "This dual expansion send compute and memory costs skyrocket-\ning, making token compression indispensable.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhy is token compression considered indispensable in this paper?\n\n材料:\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowle\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“Why is token compression considered indispensable in this paper?” 根据提供的材料，我需要仔细查看材料中的内容，看看是否有提到token compression的相关信息。\n\n首先，我注意到用户提供的材料分为几个部分，看起来像是不同论文的引用或相关研究。第一部分是关于神经网络可重编程性的论文，作者是A. Radford等人，发表在2019年和2021年。第二部分是关于领域特定数据生成框架的论文，作者是Chris Xing Tian等，发表在2025年。材料中还包含了一些其他研究的引用，比如OpenAI的模型、LlamaIndex等，但这些似乎与token compression无关。\n\n接下来，我需要检查每个引用的标题和内容，看看是否有提到token compression。第一部分的论文标题是“Neural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction”，这里讨论的是模型重编程、提示调优和提示指令，但没有提到token compression。第二部分的论文标题是“Domain-Specific Data Generation Framework for RAG Adaptation”，讨论的是RAG适应的领域特定数据生成框架，也没有提到token compression。\n\n此外，材料中还包含了一些其他研究的引用，比如关于对比预测编码的论文，但同样没有涉及token compression。因此，根据提供的材料，没有找到任何关于token compression的讨论或相关说明。\n\n用户的问题可能基于某个特定的论文，但根据提供的材料，无法确定该论文是否讨论了token compression。因此，正确的回答应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.014629049111807733, "em": 0.0, "meteor": 0.05462587626603843, "rouge_l": 0.014629049111807733}
{"id": "Vision-centric Token Compression in Large Language Model.pdf_p1_1", "question": "What is VIST's slow–fast compression framework?", "reference": "We introduce VISION CENTRIC\nTOKEN COMPRESSION (VIST), a slow–fast compression framework that mir-\nrors human reading: the fast path renders distant tokens into images, letting\na frozen, lightweight vision encoder skim the low-salience context; the slow\npath feeds the proximal window into the LLM for fine-grained reasoning.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat is VIST's slow–fast compression framework?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurificati\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What is VIST's slow–fast compression framework?” 根据提供的材料，我需要仔细查看材料中是否有相关信息。\n\n首先，我注意到用户提供的材料中有几篇论文，分别是关于RAG适应框架、Orion-RAG路径对齐混合检索以及神经网络可编程性。但问题中的VIST可能是指某个特定的框架，而材料中并没有直接提到VIST这个名称。在材料中，第一篇论文提到的是RAGen，而第二篇是Orion-RAG，第三篇是关于神经网络可编程性的。没有提到VIST的框架。\n\n接下来，我需要确认是否有可能VIST是材料中某个部分的缩写或拼写错误。例如，是否有“VIST”出现在材料中的某个部分？检查材料中的各个部分，发现没有VIST的出现。可能用户提到的VIST是其他名称的误写，或者材料中确实没有相关信息。\n\n此外，用户的问题可能涉及材料中提到的其他框架，比如RAGen或Orion-RAG，但问题明确问的是VIST的slow–fast compression framework。由于材料中没有提到VIST，因此无法根据现有材料回答这个问题。因此，正确的回答应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.03590285110876452, "em": 0.0, "meteor": 0.09046485163190561, "rouge_l": 0.01689545934530095}
{"id": "Vision-centric Token Compression in Large Language Model.pdf_p1_2", "question": "How many in-context learning benchmarks are used to evaluate VIST?", "reference": "On eleven in-context\nlearning benchmarks, VIST achieves the same accuracy with 2.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nHow many in-context learning benchmarks are used to evaluate VIST?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p4]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nPrompt\nTuning\nModel\nReprogramming\nPrompt\nInstruction\nMethodology\nResNet\nViT\nLlama\nGPT\nCLIP\nLlava\nGFM\nGNN\nArchitecture\nImage\nText\nAudio\nGraph\nProtein\nModality\nNeural Network Reprogrammability\nPre-trained models\nDownstream tasks\nFigure 3 | We introduce Neural Network Reprogrammability as a unifying framework to bring coherence\nto a set of model adaptation techniques that have often been studied in isolation. Importantly, this shared\nunderlying principle applies regardless of pre-trained model architectures and data modalities.\ntasks without internal parameter updates; whilst the adaptation is achieved by strategically manipulating the\ninputs (and/or auxiliary) information provided to the model (Chen, 2024; Elsayed et al., 2019) and the output\nmodel produces, effectively leveraging neural networks’ inherent input-output sensitivity (Lowd and Meek,\n2005) to elicit desired task-specific behaviors.\nReprogrammability provides a coherent lens through which to view three major families of work:\nmodel reprogramming (MR) (Chen, 2024; Elsayed et al., 2019), prompt tuning (PT) (Lester et al., 2021; Li and\nLiang, 2021), and in-context learning (Brown et al., 2020; Kirillov et al., 2023), which we refer to as prompt\ninstruction (PI) throughout this paper to avoid confusion with PT. Although often developed in parallel\nacross different communities, we argue that they all rely on a common underlying principle that has yet to\nbe formally recognized and consolidated. This commonality motivates grouping them under the unifying\nconcept of reprogrammability-centric adaptation (RCA). This perspective reveals the connections between\nseemingly disparate methods, showing them as variations on a common theme: the systematic exploitation\nof a neural network’s sensitivity to manipulations at its interfaces.\nWith this unified view (Figure 3), we aim to bridge previously disparate resea\n\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“How many in-context learning benchmarks are used to evaluate VIST?” 根据提供的材料，我需要仔细查看材料中的相关内容。\n\n首先，用户提到的VIST可能是指某个特定的模型或系统，但材料中并没有直接提到VIST这个名称。我需要检查提供的材料中是否有任何关于VIST的提及。\n\n材料分为三个部分：第一部分是关于RAG适应性的领域特定数据生成框架，第二部分是关于神经网络可编程性的统一主题，第三部分是关于Orion-RAG的路径对齐混合检索。这些部分都没有提到VIST或者与之相关的基准测试。\n\n接下来，我需要确认问题中的“in-context learning benchmarks”是否在材料中有相关描述。in-context learning通常指的是模型在上下文中学习的能力，可能涉及某些基准测试。但材料中提到的RAGen框架和Orion-RAG的局限性，似乎没有具体提到基准测试的数量。\n\n此外，材料中的参考文献部分也没有涉及VIST或相关基准测试的信息。因此，根据提供的材料，无法找到与VIST相关的基准测试数量的信息。\n\n因此，答案应该是无法从给定材料中确定。\n</think>\n\n无法从给定材料中确定。", "f1": 0.018018018018018018, "em": 0.0, "meteor": 0.06994630131486501, "rouge_l": 0.015765765765765764}
{"id": "Vision-centric Token Compression in Large Language Model.pdf_p2_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1: Our method VIST adopts a lightweight vision encoder to process loosely relevant long contexts, offering a more cost-efficient alternative to full LLM processing. However, the inherent redundancy in long text leads to redundant visual tokens. Motivated by Selective Reading Strategy where low-frequency (content) words receive longer fixations while high-frequency function words are often skipped, we design Probability-informed", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.03505154639175258, "em": 0.0, "meteor": 0.0996072230157111, "rouge_l": 0.02061855670103093}
{"id": "xRAG- Extreme Context Compression for Retrieval-augmented Generation with One Token.pdf_p1_0", "question": "What is xRAG introduced for?", "reference": "This paper introduces xRAG, a novel context compression method designed specif-\nically for retrieval-augmented generation.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat is xRAG introduced for?\n\n材料:\n[Orion-RAG-_Path-Aligned_Hybrid_Retrieval_for_Graphless_Data p9]\nLimitations\nWhile Orion-RAG demonstrates robust perfor-\nmance across diverse datasets, it still has some lim-\nitations: (1) Its effectiveness relies heavily on the\npresence of extractable entities within the source\ntext. In scenarios where paragraphs are highly ab-\nstract or lack distinct subjects, the generated paths\nmay become generic or sparse, potentially reduc-\ning the efficiency of the path-based index. (2) The\nframework is sensitive to hyperparameter configu-\nrations, such as chunk sizes and pruning thresholds.\nAs observed in our ablation studies, suboptimal\nsettings can lead to either aggressive signal loss\nor excessive noise accumulation, suggesting that\ndomain-specific tuning is often necessary for opti-\nmal results. (3) The performance of the rewriting\nand path generation is contingent on prompt design.\nMinor variations in instruction prompts can alter\nthe granularity of generated tags, which may affect\ndownstream retrieval precision in specialized con-\ntexts. Although these limitations highlight current\nconstraints, they also point to valuable directions\nfor future optimization and robustness research.\nReferences\nGordon V. Cormack, Charles L A Clarke, and Stefan\nBuettcher. 2009. Reciprocal rank fusion outperforms\ncondorcet and individual rank learning methods. In\nProceedings of the 32nd International ACM SIGIR\nConference on Research and Development in Infor-\nmation Retrieval, SIGIR ’09, page 758–759, New\nYork, NY, USA. Association for Computing Machin-\nery.\nJiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and\nLi Yuan. 2024. Chatlaw: Open-source legal large\nlanguage model with integrated external knowledge\nbases. In Proceedings of the 62nd Annual Meeting of\nthe Association for Computational Linguistics (ACL).\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. Preprint, arXiv:1810.04805.\nMatthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\nJohnson, Gergely\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p22]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nsizes, pre-training data); a wide array of target tasks, spanning different modalities (text, vision, multi-\nmodal), varying levels of abstraction, and diverse degrees of similarity/dissimilarity to the source\nmodel’s original task(s); standardized conditions for evaluation: data limitations (few-shot, zero-shot\nreprogramming), signal-to-noise ratios, presence of distribution shifts between reprogrammable data\nand test data, and computational budgets for learning the reprogrammed solution.\n• Defining Appropriate Baselines: Clear guidelines are necessary for choosing appropriate baselines\nwhen evaluating RCA methods. These guidelines should consider factors such as the number of\ntrainable parameters (if any), computational cost (e.g., FLOPs for training and inference), and the type\nof access to the pre-trained model (e.g., white-box vs. black-box).\n• Setting up Evaluation Metrics: Evaluations should extend beyond task-specific accuracy. Crucially,\nreasonable additional dimensions include but are not limited to robustness and stability, program\nefficiency, computational gains, and transferability of the RCA solution across different tasks.\nWithout rigorous evaluation frameworks, assessing true progress in RCA research will remain challenging,\npotentially leading to fragmented efforts and incomparable results.\n5.3. Limitations of Existing Programs\nWhile the concept of reprogrammability is appealing for its efficiency and potential, current techniques,\nparticularly those involving “prompts” (whether hard textual prompts or learned soft prompts), still exhibit\npractical limitations:\n• Data Efficiency: Although RCA avoids fin\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“What is xRAG introduced for?” 根据提供的材料，我需要仔细查看材料中的相关内容。\n\n首先，用户提供的材料中有三个不同的文档，分别是关于Orion-RAG、Domain-Specific Data Generation Framework for RAG Adaptation（RAGen）以及Neural Network Reprogrammability。问题涉及xRAG，但材料中并没有直接提到xRAG这个术语。不过，可能用户指的是Orion-RAG，因为材料中提到Orion-RAG的局限性，而问题可能是在询问Orion-RAG的用途。\n\n接下来，我需要检查材料中是否有任何关于Orion-RAG的介绍。在第一个材料中，Orion-RAG被描述为一种路径对齐的混合检索框架，用于处理图无关数据。其目的是通过路径基于的索引提高检索效率，尤其是在抽象段落或缺乏明确主题的情况下。此外，Orion-RAG的局限性包括依赖于可提取实体、对超参数敏感以及对提示设计的依赖。\n\n因此，根据材料中的信息，Orion-RAG被引入是为了在处理图无关数据时，通过路径对齐的混合检索方法提高检索效率，尤其是在数据抽象程度高或缺乏明确主题的情况下。不过，材料中并没有明确提到xRAG，可能用户有拼写错误，或者xRAG是Orion-RAG的别称。如果按照材料中的内容，回答应基于Orion-RAG的用途。\n\n但需要确认是否材料中确实提到了xRAG。在提供的材料中，没有出现xRAG这个词，只有Orion-RAG。因此，可能用户的问题存在错误，或者xRAG是Orion-RAG的别称。如果按照材料中的内容，回答Orion-RAG的用途，而问题中的xRAG可能是一个错误，那么答案应基于Orion-RAG的描述。\n\n因此，综合材料中的信息，xRAG（假设为Orion-RAG）被引入是为了在处理图无关数据时，通过路径对齐的混合检索方法提高检索效率，尤其是在数据抽象程度高或缺乏明确主题的情况下。因此，答案应基于这一点。\n</think>\n\n无法从给定材料中确定。材料中提到的“xRAG”未被提及，且未明确其定义或用途。提供的材料主要讨论了Orion-RAG（可能为xRAG的误写）的局限性和应用场景，但未直接说明xRAG的具体引入目的。", "f1": 0.015486725663716814, "em": 0.0, "meteor": 0.058593750000000014, "rouge_l": 0.011061946902654867}
{"id": "xRAG- Extreme Context Compression for Retrieval-augmented Generation with One Token.pdf_p1_1", "question": "In xRAG, what is the only trainable component?", "reference": "In xRAG, the modality bridge is the only\ntrainable component, while the retriever and language model remain frozen.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nIn xRAG, what is the only trainable component?\n\n材料:\n[Long-Context_Language_Modeling_with_Parallel_Context_Encoding p11]\nAlexis Chevalier, Alexander Wettig, Anirudh Ajith, and\nDanqi Chen. 2023. Adapting language models to\ncompress contexts. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 3829–3846, Singapore. Associa-\ntion for Computational Linguistics.\nKrzysztof Marcin Choromanski, Valerii Likhosherstov,\nDavid Dohan, Xingyou Song, Andreea Gane, Tamas\nSarlos, Peter Hawkins, Jared Quincy Davis, Afroz\nMohiuddin, Lukasz Kaiser, David Benjamin Be-\nlanger, Lucy J Colwell, and Adrian Weller. 2021.\nRethinking attention with performers. In Interna-\ntional Conference on Learning Representations.\nPradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,\nNoah A. Smith, and Matt Gardner. 2021. A dataset\nof information-seeking questions and answers an-\nchored in research papers. In Proceedings of the\n2021 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 4599–4610, On-\nline. Association for Computational Linguistics.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional Transformers for language under-\nstanding. In North American Chapter of the Associa-\ntion for Computational Linguistics (NAACL).\nYao Fu, Rameswar Panda, Xinyao Niu, Xiang Yue, Han-\nnaneh Hajishirzi, Yoon Kim, and Hao Peng. 2024.\nData engineering for scaling language models to 128k\ncontext.\nTianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\n2023. Enabling large language models to generate\ntext with citations. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 6465–6488, Singapore. Associa-\ntion for Computational Linguistics.\nAlbert Gu and Tri Dao. 2023. Mamba: Linear-time\nsequence modeling with selective state spaces.\nAlbert Gu, Karan Goel, and Christopher Re. 2022. Ef-\nficiently modeling long sequences with structured\nstate spaces. In International Conference on Learn-\ning Representations.\nKelvin Guu, Kento\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowl\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“In xRAG, what is the only trainable component?” 根据提供的材料，我需要仔细查找相关信息。\n\n首先，用户提到的xRAG可能是指材料中提到的某个特定框架或模型。在材料中，有几处提到了RAG相关的内容，比如“RAGen”是一个生成域特定问题-答案-上下文（QAC）三元组的框架。但问题中的xRAG可能是指另一个框架，比如材料中提到的“Domain-Specific Data Generation Framework for RAG Adaptation”中的RAG，但不确定是否是xRAG。\n\n接下来，我需要检查材料中是否有直接提到xRAG的组件。在材料的最后部分，有一段提到：“RAGen supports multiple RAG adaptation strategies, including the optimization of key components such as the LLM, retriever, and embedding model, etc.” 这里提到的LLM（大型语言模型）、retriever（检索器）和embedding model（嵌入模型）是RAG中的关键组件。但问题中的xRAG是否与这些组件有关呢？\n\n另外，材料中还提到了“Neural Network Reprogrammability”和“Prompt Tuning”等主题，但这些可能与xRAG无关。需要确认xRAG是否在材料中被提及。根据提供的材料，xRAG可能是指RAGen框架，而问题中的“only trainable component”可能指的是该框架中的某个特定组件。\n\n在材料中，RAGen的描述中提到它支持多种RAG适应策略，包括优化关键组件如LLM、retriever和embedding model。因此，如果xRAG指的是RAGen框架，那么其唯一的可训练组件可能是指这些关键组件中的一个。但问题问的是“only trainable component”，即唯一可训练的组件，可能需要确定是否只有其中一个组件是可训练的，或者是否有其他组件。\n\n不过，根据材料中的描述，RAGen的模块化管道包括语义分块、层次概念提取和多块检索，以及引入 curated distractor contexts。这可能意味着这些组件都是可训练的，但问题问的是“only trainable component”，即唯一可训练的组件。如果材料中没有明确说明，可能需要进一步分析。\n\n但根据材料中的描述，RAGen支持优化关键组件如LLM、retriever和embedding model，这可能意味着这些是可训练的，而其他组件可能不是。但问题中的“only”可能意味着只有一个组件是可训练的，而其他不是。但材料中并没有明确说明，因此可能无法确定。\n\n不过，用户提供的材料中可能没有明确指出xRAG的唯一可训练组件，因此可能需要根据材料中的信息推断。例如，如果xRAG指的是RAGen框架，而其关键组件是LLM、retriever和embedding model，那么可能这三个都是可训练的，但问题问的是“only”，所以可能需要进一步确认。\n\n但根据材料中的描述，RAGen支持优化这些组件，因此可能这三个都是可训练的，但问题中的“only”可能意味着只有一个，所以可能需要重新检查材料是否有其他信息。\n\n最终，可能材料中没有明确说明xRAG的唯一可训练组件，因此无法确定答案，应回答“无法从给定材料中确定”。\n</think>\n\n无法从给定材料中确定。", "f1": 0.020242914979757085, "em": 0.0, "meteor": 0.05735559566787003, "rouge_l": 0.018218623481781375}
{"id": "xRAG- Extreme Context Compression for Retrieval-augmented Generation with One Token.pdf_p1_2", "question": "What average improvement is reported and across how many tasks?", "reference": "average improvement of over 10% across six\nknowledge-intensive tasks, compatible with various language model backbones,\nranging from a dense 7B model to an 8x7B Mixture of Experts configuration.", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nWhat average improvement is reported and across how many tasks?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nanayakkara. 2023. Improving the domain\nadaptation of retrieval augmented generation (rag)\nmodels for open domain question answering. Trans-\nactions of the Association for Computational Linguis-\ntics, 11:1–17.\nHuatong Song, Jinhao Jiang, Yingqian M\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p32]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nC. Zhang, J. Cho, F. D. Puspitasari, S. Zheng, C. Li, Y. Qiao, T. Kang, X. Shan, C. Zhang, C. Qin, F. Rameau,\nL.-H. Lee, S.-H. Bae, and C. S. Hong. A survey on segment anything model (sam): Vision foundation\nmodel meets prompt engineering. arXiv preprint arXiv:2306.06211, 2023a.\nJ. Zhang, B. I. Rubinstein, J. Zhang, and F. Liu. One stone, two birds: Enhancing adversarial defense through\nthe lens of distributional discrepancy. In ICML, 2025.\nN. Zhang, L. Li, X. Chen, S. Deng, Z. Bi, C. Tan, F. Huang, and H. Chen. Differentiable prompt makes\npre-trained language models better few-shot learners. In ICLR, 2022.\nT. Zhang, X. Li, H. Fei, H. Yuan, S. Wu, S. Ji, C. C. Loy, and S. Yan. Omg-llava: Bridging image-level,\nobject-level, pixel-level reasoning and understanding. In NeurIPS, 2024a.\nY. Zhang, K. Zhou, and Z. Liu. What makes good examples for visual in-context learning? In NeurIPS.\nCurran Associates, Inc., 2023b.\nY. Zhang, Y. Dong, S. Zhang, T. Min, H. Su, and J. Zhu. Exploring the transferability of visual prompting for\nmultimodal large language models. In CVPR, pages 26562–26572, 2024b.\nY. Zhang, H. Li, Y. Yao, A. Chen, S. Zhang, P.-Y. Chen, M. Wang, and S. Liu. Visual prompting reimagined:\nThe power of activation prompts. 2024c.\nW. X. Zhao, X. Liu, J. Zhang, Y. Zhang, K. Zhou, and J.-R. Wen. A comprehensive survey on pretrained\nfoundation models: A history from BERT to ChatGPT. arXiv preprint arXiv:2302.09419, 2023.\nZ. Zhao, E. Wallace, S. Feng, D. Klein, and S. Singh. Calibrate before use: Improving few-shot performance\nof language models. In ICML, 2021.\nH. Zheng, Q. Wang, Z\n\n答案:\nassistant\n<think>\nOkay, let's see. The user is asking about the average improvement reported and across how many tasks based on the provided material. Hmm, I need to check the materials given.\n\nLooking through the text, there are several entries. The first one mentions \"LlamaIndex. 2025. Llamaindex datasetgenerator.\" But that's a bit unclear. Then there's a reference to \"When not to trust language models...\" which is a paper from 2022. Another one is about OpenAI's ChatGPT4o and the embedding API. Then there's a 2024 paper by Crystal Qian et al. about the evolution of LLM adoption in industry data curation practices. \n\nWait, the user is asking about average improvement and the number of tasks. The materials provided seem to be a list of papers and references, but none of them mention any specific experiments or studies that report average improvements across tasks. The references are about research papers, but they don't talk about performance metrics or task counts. \n\nI don't see any mention of datasets, evaluation metrics, or comparative analysis. The only mention of tasks is in the title of a paper, like \"Improving the domain adaptation of retrieval augmented generation (RAG) models for open domain question answering\" which mentions tasks in the context of RAG, but the actual data isn't provided here. \n\nSince the question is about average improvement and the number of tasks, and the materials don't include any data or results that answer this, the answer should be that it's not possible to determine from the given information.\n</think>\n\n无法从给定材料中确定。", "f1": 0.021775544388609715, "em": 0.0, "meteor": 0.0631363278171789, "rouge_l": 0.016750418760469014}
{"id": "xRAG- Extreme Context Compression for Retrieval-augmented Generation with One Token.pdf_p2_3", "question": "According to Figure 1, what does it describe?", "reference": "Figure 1: xRAG enables efficient retrieval augmentation by adding one document token [X]. compression is applied on the surface form. These approaches, however, either require significant memory for storing LLM activations (e.g., 1.05 MB per token as reported by [58]) or suffer from relatively low compression rates. More critically, these methods overlook a crucial characteristic", "prediction": "system\n你是一个严谨的问答助手，只能基于给定材料回答。\nuser\n请根据材料回答问题。若材料不足以确定答案，请回答“无法从给定材料中确定”。\n\n问题:\nAccording to Figure 1, what does it describe?\n\n材料:\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p1]\nDomain-Specific Data Generation Framework for RAG Adaptation\nChris Xing Tian1*\nWeihao Xie2*\nZhen Chen2\nZhengyuan Yi2,\nHui Liu2\nHaoliang Li2\nShiqi Wang2\nSiwei Ma3\n1Peng Cheng Laboratory, Shenzhen, China\n2City University of Hong Kong, Hong Kong SAR\n3Peking University, Beijing, China\ntxsing@live.com, swma@pku.edu.cn\n{weihaxie-c, zchen979-c, liuhui3-c}@my.cityu.edu.hk\n{zhengyyi, haoliang.li, shiqwang}@cityu.edu.hk\nAbstract\nRetrieval-Augmented Generation (RAG) com-\nbines the language understanding and reason-\ning power of large language models (LLMs)\nwith external retrieval to enable domain-\ngrounded responses. Effectively adapting RAG\nsystems to domain-specific settings requires\nspecialized, context-rich training data beyond\ngeneral-purpose question-answering. Here, we\npropose RAGen, a scalable and modular frame-\nwork for generating domain-grounded ques-\ntion–answer–context (QAC) triples tailored\nto diverse RAG adaptation approaches. RA-\nGen produces these QAC triples by identify-\ning key concepts in documents, generating di-\nverse questions guided by Bloom’s Taxonomy-\ninspired principles, and pairing them with\nprecise answers extracted from relevant con-\ntexts. RAGen supports multiple RAG adap-\ntation strategies, including the optimization of\nkey components such as the LLM, retriever, and\nembedding model, etc. Its modular pipeline fea-\ntures semantic chunking, hierarchical concept\nextraction, and multi-chunk retrieval, along\nwith the introduction of curated distractor con-\ntexts to promote robust reasoning. Designed for\nscalability, RAGen efficiently handles large and\nevolving document corpora without redundant\nprocessing, making it especially suitable for\ndynamic evolving domains such as scientific\nresearch and enterprise knowledge bases.\n1\nIntroduction\nWith the growing adoption of large language mod-\nels (LLMs) in enterprise and organizational set-\ntings, there is increasing demand for integrat-\ning these models into domain-specific workflows\n(Chiarello et al., 2024;\n\n[Neural_Network_Reprogrammability-_A_Unified_Theme_on_Model_Reprogramming__Prompt_Tuning__and_Prompt_ p30]\nNeural Network Reprogrammability: A Unified Theme on Model Reprogramming, Prompt Tuning, and Prompt Instruction\nA. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, et al. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8):9, 2019.\nA. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark,\net al. Learning transferable visual models from natural language supervision. In ICML, 2021.\nV. Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai, J. Chaffin, K. Liu, et al. Multitask prompted\ntraining enables zero-shot task generalization. In ICLR, 2022.\nS. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li, A. Gupta, H. Han, S. Schulhoff, P. S.\nDulepet, S. Vidyadhara, D. Ki, S. Agrawal, C. Pham, G. Kroiz, F. Li, H. Tao, A. Srivastava, H. D. Costa,\nS. Gupta, M. L. Rogers, I. Goncearenco, G. Sarli, I. Galynker, D. Peskoff, M. Carpuat, J. White, S. Anadkat,\nA. Hoyle, and P. Resnik. The prompt report: A systematic survey of prompting techniques. arXiv preprint\narXiv:2406.06608, 2024.\nT. Shin, Y. Razeghi, R. L. Logan IV, E. Wallace, and S. Singh. AutoPrompt: Eliciting knowledge from language\nmodels with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods\nin Natural Language Processing (EMNLP), 2020.\nN. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao. Reflexion: Language agents with\nverbal reinforcement learning. In NeurIPS, 2023.\nA. Shtedritski, C. Rupprecht, and A. Vedaldi. What does clip know about a red circle? visual prompt\nengineering for vlms. In ICCV, 2023.\nY. Sun, J. Zhang, Z. Ye, C. Xiao, and F. Liu. Sample-specific noise injection for diffusion-based adversarial\npurification. In ICML, 2025.\nY.-L. Sung, J. Cho, and M. Bansal. Vl-adapter: Parameter-efficient transfer learning for vision-and-language\ntasks. In CVPR, 2022.\nC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Int\n\n[Domain-Specific_Data_Generation_Framework_for_RAG_Adaptation p10]\npages 2623–2641, Vienna, Austria. Association for\nComputational Linguistics.\nLlamaIndex. 2025.\nLlamaindex datasetgenerator.\nhttps://developers.llamaindex.ai/python/\nframework-api-reference/evaluation/\ndataset_generation/.\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\nDaniel Khashabi, and Hannaneh Hajishirzi. 2022.\nWhen not to trust language models: Investigating\neffectiveness of parametric and non-parametric mem-\nories. arXiv preprint arXiv:2212.10511.\nAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.\nRepresentation learning with contrastive predictive\ncoding. arXiv preprint arXiv:1807.03748.\nOpenAI. 2025a.\nOpenai chatgpt4o.\nhttps:\n//platform.openai.com/docs/models/\nchatgpt-4o-latest.\nOpenAI.\n2025b.\nOpenai\nembedding\napi.\nhttps://platform.openai.com/docs/models/\ntext-embedding-ada-002.\nCrystal Qian, Michael Xieyang Liu, Emily Reif, Grady\nSimon, Nada Hussein, Nathan Clement, James\nWexler, Carrie J Cai, Michael Terry, and Minsuk\nKahng. 2024.\nThe evolution of llm adoption in\nindustry data curation practices.\narXiv preprint\narXiv:2412.16089.\nQwen, An Yang, Baosong Yang, Beichen Zhang,\nBinyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\nDayiheng Liu, Fei Huang, Haoran Wei, Huan Lin,\nJian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Yang,\nJiaxi Yang, Jingren Zhou, Junyang Lin, and 24 others.\n2025. Qwen2.5 Technical Report. arXiv preprint.\nArXiv:2412.15115 [cs].\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine\nLee, Sharan Narang, Michael Matena, Yanqi Zhou,\nWei Li, and Peter J Liu. 2020. Exploring the lim-\nits of transfer learning with a unified text-to-text\ntransformer. Journal of machine learning research,\n21(140):1–67.\nShamane Siriwardhana, Rivindu Weerasekera, Elliott\nWen, Tharindu Kaluarachchi, Rajib Rana, and\nSuranga Nana\n\n答案:\nassistant\n<think>\n好的，我现在需要回答用户的问题：“According to Figure 1, what does it describe?” 用户提供的材料中有几段内容，但并没有提到具体的Figure 1。首先，我需要仔细检查所有提供的材料，看看是否有任何地方提到Figure 1或者与之相关的描述。\n\n首先，用户提供的材料分为几个部分，包括论文的摘要、引言、参考文献等。第一段是关于RAG适应的领域特定数据生成框架，作者是Chris Xing Tian等人。接着是另一篇关于神经网络可编程性的论文，以及一些参考文献。这些内容都是学术论文的章节，但没有提到任何图表或图示。\n\n接下来，我需要确认用户是否在问题中提到的Figure 1是否存在于材料中。根据用户提供的材料，所有内容都是文本，没有图像或图表的描述。因此，无法从给定的材料中确定Figure 1的内容。\n\n此外，用户可能误以为材料中有Figure 1，但实际上材料中没有这样的内容。因此，正确的回答应该是无法从给定材料中确定答案。\n</think>\n\n无法从给定材料中确定。", "f1": 0.043523316062176166, "em": 0.0, "meteor": 0.09608540925266904, "rouge_l": 0.02072538860103627}
